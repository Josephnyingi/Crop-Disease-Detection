{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Josephnyingi/Crop-Disease-Detection/blob/main/Crop_disease_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2MK8FdU3mM6"
      },
      "source": [
        "#Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qfBE2jk4AVC"
      },
      "source": [
        "Plants are susceptible to diseases due to factors such as fertilizer use, farming practices, and environmental conditions, which negatively impact agricultural yields and the economy. Early detection of plant diseases is crucial for farmers to cultivate crops effectively and efficiently, both in terms of quality and quantity. Thus, disease detection in plants is a vital aspect of agriculture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWSGk8rn4msW"
      },
      "source": [
        "# Download dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAhw4b_m4xjd"
      },
      "source": [
        "Initially, we retrieve the PlantVillage dataset from Google Drive using its unique ID, then extract the contents of the downloaded PlantVillage.zip file into the designated PlantVillage dataset folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcK-u7WwAA-8"
      },
      "source": [
        "# Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Library\n",
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install gdown\n",
        "!apt-get update && apt-get install fil\n",
        "!pip install keras_preprocessing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQIWYPsnVoOS",
        "outputId": "7c078c1a-9063-43f2-f59a-f10e759e2d4e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [71.6 kB]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,297 kB]\n",
            "Hit:16 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,496 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,392 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,970 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [998 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,134 kB]\n",
            "Fetched 11.7 MB in 7s (1,726 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package fil\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras_preprocessing) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from keras_preprocessing) (1.15.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "lWPULaLOXlym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Mount your Google Drive:"
      ],
      "metadata": {
        "id": "ojpcXTR9X2AD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj7yE6v562ns",
        "outputId": "2e7c783b-d468-4f0b-a708-b1e713101e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copied the dataset to Google Drive: Downloaded the dataset and saved it to Google Drive.\n",
        "Then accessed the dataset in Colab "
      ],
      "metadata": {
        "id": "De-sKSvsZx4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/crowdai')"
      ],
      "metadata": {
        "id": "cXvqtvaDNd9G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing a few parameters required for the image dataset preprocessing."
      ],
      "metadata": {
        "id": "XzygYZxYLobP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimension of resized image\n",
        "DEFAULT_IMAGE_SIZE = tuple((256, 256))\n",
        "\n",
        "# Number of images used to train the model\n",
        "N_IMAGES = 100\n",
        "\n",
        "# Path to the dataset folder\n",
        "root_dir = '/content/gdrive/MyDrive/crowdai'\n",
        "\n",
        "train_dir = os.path.join(root_dir, 'train')\n",
        "val_dir = os.path.join(root_dir, 'val')"
      ],
      "metadata": {
        "id": "f-570aJXNzD4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None:\n",
        "            image = cv2.resize(image, DEFAULT_IMAGE_SIZE)   \n",
        "            return img_to_array(image)\n",
        "        else:\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "-wjT90OyMKSJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Set the path to the dataset directory\n",
        "dataset_path = \"/content/gdrive/MyDrive/crowdai\"\n",
        "\n",
        "# Get the list of image filenames and their corresponding labels\n",
        "image_list = os.listdir(dataset_path)\n",
        "label_list = [os.path.basename(os.path.dirname(os.path.join(dataset_path, image))) for image in image_list]\n",
        "\n",
        "# Use LabelBinarizer to convert the string labels to binary labels\n",
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "\n",
        "# Create an empty list to store the preprocessed image data\n",
        "preprocessed_images = []\n",
        "\n",
        "# Loop through the image filenames\n",
        "for image_filename in image_list:\n",
        "    # Read the image using OpenCV\n",
        "    image = cv2.imread(os.path.join(dataset_path, image_filename))\n",
        "\n",
        "    # Check if the image was successfully read\n",
        "    if image is not None:\n",
        "        # Resize the image to a fixed size (e.g., 224x224)\n",
        "        resized_image = cv2.resize(image, (224, 224))\n",
        "        # Convert the image to a NumPy array and normalize the pixel values\n",
        "        preprocessed_image = np.array(resized_image, dtype=np.float16) / 225.0\n",
        "        # Add the preprocessed image to the list\n",
        "        preprocessed_images.append(preprocessed_image)\n",
        "    else:\n",
        "        print(f\"Failed to read image: {image_filename}\")\n",
        "\n",
        "# Convert the list of preprocessed images to a NumPy array\n",
        "np_image_list = np.array(preprocessed_images)\n",
        "\n",
        "# Check the number of images loaded for training\n",
        "image_len = len(image_list)\n",
        "print(f\"Total number of images: {image_len}\")\n",
        "\n",
        "# Check the shape of the image data and label data\n",
        "print(f\"Image data shape: {np_image_list.shape}\")\n",
        "print(f\"Label data shape: {image_labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nFkBlPlSjsI",
        "outputId": "9543dc74-9106-401b-edc4-00dd718557c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to read image: c_4\n",
            "Failed to read image: c_2\n",
            "Failed to read image: c_5\n",
            "Failed to read image: c_21\n",
            "Failed to read image: c_32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Define the paths to your dataset\n",
        "train_dir = '/content/gdrive/MyDrive/crowdai'\n",
        "valid_dir = '/content/gdrive/MyDrive/crowdai'\n",
        "\n",
        "# Define the image data generator with optional data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Use flow_from_directory to load the image data and labels\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Get the number of classes\n",
        "num_classes = len(train_generator.class_indices)\n",
        "\n",
        "# Align the image and label data into numpy arrays\n",
        "train_samples = len(train_generator.filenames)\n",
        "train_image_array = np.zeros((train_samples, 224, 224, 3), dtype=np.float32)\n",
        "train_label_array = np.zeros((train_samples, num_classes), dtype=np.float32)\n",
        "\n",
        "for i in range(0, train_samples, train_generator.batch_size):\n",
        "    images, labels = train_generator.next()\n",
        "    batch_size = images.shape[0]\n",
        "    train_image_array[i:i+batch_size] = images\n",
        "    train_label_array[i:i+batch_size] = labels\n",
        "\n",
        "valid_samples = len(valid_generator.filenames)\n",
        "valid_image_array = np.zeros((valid_samples, 224, 224, 3), dtype=np.float32)\n",
        "valid_label_array = np.zeros((valid_samples, num_classes), dtype=np.float32)\n",
        "\n",
        "for i in range(0, valid_samples, valid_generator.batch_size):\n",
        "    images, labels = valid_generator.next()\n",
        "    batch_size = images.shape[0]\n",
        "    valid_image_array[i:i+batch_size] = images\n",
        "    valid_label_array[i:i+batch_size] = labels\n",
        "# Use LabelBinarizer to binarize the labels\n",
        "label_binarizer = LabelBinarizer()\n",
        "train_label_array = label_binarizer.fit_transform(np.argmax(train_label_array, axis=1))\n",
        "valid_label_array = label_binarizer.transform(np.argmax(valid_label_array, axis=1))\n"
      ],
      "metadata": {
        "id": "QDe1iaC8YSO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counting Total number of images "
      ],
      "metadata": {
        "id": "CjIFyBKHMWs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the root directory of the Plant Village dataset\n",
        "dataset_path = '/content/gdrive/MyDrive/crowdai'\n",
        "\n",
        "# Initialize a count of the number of images\n",
        "count = 0\n",
        "\n",
        "# Loop through the subdirectories of the dataset path\n",
        "for subdir, dirs, files in os.walk(dataset_path):\n",
        "    # Loop through the files in the subdirectory\n",
        "    for file in files:\n",
        "        # Check if the file is an image file with a .jpg or .png extension\n",
        "        if file.endswith('.jpg') or file.endswith('.png'):\n",
        "            # Increment the count of images\n",
        "            count += 1\n",
        "\n",
        "# Print the count of images\n",
        "print('Number of images:', count)\n"
      ],
      "metadata": {
        "id": "wkXhrDRcQ_TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking distribution of labels"
      ],
      "metadata": {
        "id": "NWKX1xPIcThC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checked the distribution of labels in a dataset as it is an important step in preparing the data for machine learning. This can help you determine if the dataset is balanced or imbalanced, which can have an impact on the performance of your model.\n",
        "\n",
        "To check the distribution of labels in the Plant Village dataset, you can use the following code:"
      ],
      "metadata": {
        "id": "gZg01x-Qcm1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load the data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "wpcM_KKvN28d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking the distribution of labels in a dataset is an important step in preparing the data for machine learning. This can help you determine if the dataset is balanced or imbalanced, which can have an impact on the performance of your model.\n",
        "The code uses the numpy library to count the number of occurrences of each label in the y_train array. The unique_labels variable contains the unique labels in the array, and the count_labels variable contains the number of occurrences of each label.\n"
      ],
      "metadata": {
        "id": "_nmJvT9oPhoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the number of occurrences of each label\n",
        "unique_labels, count_labels = np.unique(y_train, return_counts=True)\n",
        "\n",
        "# Plot the distribution of labels\n",
        "plt.bar(unique_labels, count_labels)\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Labels\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Lid0s4qaPRxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing data"
      ],
      "metadata": {
        "id": "kD9-_O0k8-kD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Splitting the data into training and validation sets: use the train_test_split function from the scikit-learn library to split data into training and validation sets. This allos to evaluate model's performance on a validation set, which is unseen data."
      ],
      "metadata": {
        "id": "9ImnjGrb-9Q8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Total number of classes"
      ],
      "metadata": {
        "id": "ELX0TISUN64A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To examine the labels/classes in the crowdia directory read the names of the subdirectories in the dataset directory. Each subdirectory corresponds to a different class or label in the dataset. Here is how i get the list of classes in the dataset"
      ],
      "metadata": {
        "id": "BSJKLFzqRRqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the directory path to the Plant Village dataset\n",
        "data_dir = '/content/gdrive/MyDrive/crowdai'\n",
        "\n",
        "# Get the list of subdirectories in the dataset directory\n",
        "classes = os.listdir(data_dir)\n",
        "\n",
        "# Get the total number of classes\n",
        "num_classes = len(classes)\n",
        "\n",
        "# Print the total number of classes\n",
        "print(f'The Plant Village dataset contains {num_classes} classes')\n",
        "\n"
      ],
      "metadata": {
        "id": "UIIhHWN0ObGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "augment = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
        "                             height_shift_range=0.1, shear_range=0.2, \n",
        "                             zoom_range=0.2, horizontal_flip=True, \n",
        "                             fill_mode=\"nearest\")"
      ],
      "metadata": {
        "id": "CZIffdbtTnqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Splitting data to train and test...\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42)\n"
      ],
      "metadata": {
        "id": "hB3CPKzaUfa-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}