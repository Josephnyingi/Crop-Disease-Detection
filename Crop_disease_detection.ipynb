{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Josephnyingi/Crop-Disease-Detection/blob/main/Crop_disease_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2MK8FdU3mM6"
      },
      "source": [
        "#Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qfBE2jk4AVC"
      },
      "source": [
        "Plants are susceptible to diseases due to factors such as fertilizer use, farming practices, and environmental conditions, which negatively impact agricultural yields and the economy. Early detection of plant diseases is crucial for farmers to cultivate crops effectively and efficiently, both in terms of quality and quantity. Thus, disease detection in plants is a vital aspect of agriculture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWSGk8rn4msW"
      },
      "source": [
        "# Download dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAhw4b_m4xjd"
      },
      "source": [
        "Initially, we retrieve the PlantVillage dataset from Google Drive using its unique ID, then extract the contents of the downloaded PlantVillage.zip file into the designated PlantVillage dataset folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcK-u7WwAA-8"
      },
      "source": [
        "# Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Library\n",
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install gdown\n",
        "!apt-get update && apt-get install fil\n",
        "!pip install keras_preprocessing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQIWYPsnVoOS",
        "outputId": "97c48dfb-fba5-43e9-f888-b6edfa0b97f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,480 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,966 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease [24.3 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [995 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,296 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,062 kB]\n",
            "Hit:19 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,386 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,131 kB]\n",
            "Get:22 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal/main amd64 Packages [42.8 kB]\n",
            "Fetched 13.7 MB in 7s (1,900 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package fil\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from keras_preprocessing) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras_preprocessing) (1.21.6)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "lWPULaLOXlym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Mount your Google Drive:"
      ],
      "metadata": {
        "id": "ojpcXTR9X2AD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj7yE6v562ns",
        "outputId": "0b1655fa-6f55-46a4-b1b7-8985f96377e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copied the dataset to Google Drive: Downloaded the dataset and saved it to Google Drive.\n",
        "Then accessed the dataset in Colab "
      ],
      "metadata": {
        "id": "De-sKSvsZx4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/crowdai')"
      ],
      "metadata": {
        "id": "cXvqtvaDNd9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Dataframe"
      ],
      "metadata": {
        "id": "_DvjDMRMFSqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "created a DataFrame to store the image paths and labels by manually constructing the DataFrame row by row, and using a script to loop through the directory structure and extract the information"
      ],
      "metadata": {
        "id": "bP8AGNBJHFJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the path to the root directory of the Plant Village dataset\n",
        "dataset_path = '/content/gdrive/MyDrive/crowdai'\n",
        "\n",
        "# Create a list to store the image paths and labels\n",
        "data = []\n",
        "\n",
        "# Loop through the subdirectories of the dataset path\n",
        "for subdir, dirs, files in os.walk(dataset_path):\n",
        "    # Loop through the files in the subdirectory\n",
        "    for file in files:\n",
        "        # Check if the file is an image file\n",
        "        if file.endswith('.jpg') or file.endswith('.png'):\n",
        "            # Get the full path to the image file\n",
        "            file_path = os.path.join(subdir, file)\n",
        "            # Get the label for the image file by extracting the subdirectory name\n",
        "            label = os.path.basename(subdir)\n",
        "            # Add the image path and label to the list\n",
        "            data.append([file_path, label])\n",
        "\n",
        "# Create a DataFrame from the list of data\n",
        "df = pd.DataFrame(data, columns=['image_path', 'label'])\n",
        "\n",
        "# Show the first 5 rows of the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6W6GlpIEfeF",
        "outputId": "45d8cf26-b7e3-4034-83c8-2a0e3f82f939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          image_path label\n",
            "0  /content/gdrive/MyDrive/crowdai/c_4/21ad2360-4...   c_4\n",
            "1  /content/gdrive/MyDrive/crowdai/c_4/587d9e51-8...   c_4\n",
            "2  /content/gdrive/MyDrive/crowdai/c_4/c3516034-3...   c_4\n",
            "3  /content/gdrive/MyDrive/crowdai/c_4/11dc114c-5...   c_4\n",
            "4  /content/gdrive/MyDrive/crowdai/c_4/b15f23b2-4...   c_4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counting Total number of images "
      ],
      "metadata": {
        "id": "CjIFyBKHMWs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the root directory of the Plant Village dataset\n",
        "dataset_path = '/content/gdrive/MyDrive/crowdai'\n",
        "\n",
        "# Initialize a count of the number of images\n",
        "count = 0\n",
        "\n",
        "# Loop through the subdirectories of the dataset path\n",
        "for subdir, dirs, files in os.walk(dataset_path):\n",
        "    # Loop through the files in the subdirectory\n",
        "    for file in files:\n",
        "        # Check if the file is an image file with a .jpg or .png extension\n",
        "        if file.endswith('.jpg') or file.endswith('.png'):\n",
        "            # Increment the count of images\n",
        "            count += 1\n",
        "\n",
        "# Print the count of images\n",
        "print('Number of images:', count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkXhrDRcQ_TY",
        "outputId": "d21345d6-6d85-4f33-9896-a75e8e214bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 24842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total number of 'png' images"
      ],
      "metadata": {
        "id": "p-b5l4ZNR-3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Define the path to the root directory of the Plant Village dataset\n",
        "dataset_path = '/content/gdrive/MyDrive/crowdai'\n",
        "\n",
        "# Initialize a count of the number of images\n",
        "count = 0\n",
        "\n",
        "# Loop through the subdirectories of the dataset path\n",
        "for subdir, dirs, files in os.walk(dataset_path):\n",
        "    # Loop through the files in the subdirectory\n",
        "    for file in files:\n",
        "        # Check if the file is not already a .png file\n",
        "        if not file.endswith('.png'):\n",
        "            # Open the image file\n",
        "            img = Image.open(os.path.join(subdir, file))\n",
        "            # Convert the image to .png format\n",
        "            img = img.convert('RGB')\n",
        "            # Save the converted image with a .png extension\n",
        "            new_file_name = os.path.splitext(file)[0] + '.png'\n",
        "            img.save(os.path.join(subdir, new_file_name))\n",
        "        # Check if the file is a .png file\n",
        "        if file.endswith('.png'):\n",
        "            # Increment the count of images\n",
        "            count += 1\n",
        "\n",
        "# Print the count of images\n",
        "print('Number of images:', count)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuLyABXmKw7t",
        "outputId": "995f064b-5a82-479d-8ae9-3b3c0ed17634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 21917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking distribution of labels"
      ],
      "metadata": {
        "id": "NWKX1xPIcThC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checked the distribution of labels in a dataset as it is an important step in preparing the data for machine learning. This can help you determine if the dataset is balanced or imbalanced, which can have an impact on the performance of your model.\n",
        "\n",
        "To check the distribution of labels in the Plant Village dataset, you can use the following code:"
      ],
      "metadata": {
        "id": "gZg01x-Qcm1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load the data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpcM_KKvN28d",
        "outputId": "f314e2e0-b1de-4c96-d83f-59fe9c0d9ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 11s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking the distribution of labels in a dataset is an important step in preparing the data for machine learning. This can help you determine if the dataset is balanced or imbalanced, which can have an impact on the performance of your model.\n",
        "The code uses the numpy library to count the number of occurrences of each label in the y_train array. The unique_labels variable contains the unique labels in the array, and the count_labels variable contains the number of occurrences of each label.\n"
      ],
      "metadata": {
        "id": "_nmJvT9oPhoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the number of occurrences of each label\n",
        "unique_labels, count_labels = np.unique(y_train, return_counts=True)\n",
        "\n",
        "# Plot the distribution of labels\n",
        "plt.bar(unique_labels, count_labels)\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Labels\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Lid0s4qaPRxA",
        "outputId": "3d198562-dc18-43b0-c192-f935327df5b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing data"
      ],
      "metadata": {
        "id": "kD9-_O0k8-kD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After checking the distribution of labels in the dataset, the next step is to pre-process the data for use in machine learning model. This typically involves the following steps:"
      ],
      "metadata": {
        "id": "YKWwe_RB-r1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Splitting the data into training and validation sets: use the train_test_split function from the scikit-learn library to split data into training and validation sets. This allos to evaluate model's performance on a validation set, which is unseen data."
      ],
      "metadata": {
        "id": "9ImnjGrb-9Q8"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}